{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Чтение, нормализация, удаление стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import re\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Iterator\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from yargy.tokenizer import MorphTokenizer\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Text:\n",
    "    label: str\n",
    "    title: str\n",
    "    content: str\n",
    "\n",
    "\n",
    "def read_texts(fn: str) -> Iterator[Text]:\n",
    "    with gzip.open(fn, \"rt\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            yield Text(*line.strip().split(\"\\t\"))\n",
    "\n",
    "\n",
    "tokenizer = MorphTokenizer()\n",
    "ru_stopwords = set(stopwords.words(\"russian\"))\n",
    "\n",
    "def normalize_text(text: str) -> str:\n",
    "    # убираем знаки препинания\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    # нормализация и убираем стоп-слова\n",
    "    tokens = [\n",
    "        tok.normalized for tok in tokenizer(' '.join(words))\n",
    "        if (tok.normalized not in ru_stopwords) and (re.fullmatch(r'\\b\\w+\\b', tok.normalized))\n",
    "    ]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '../../data/news.txt.gz'\n",
    "texts = list(read_texts(filepath))\n",
    "\n",
    "corpus = [normalize_text(doc.content) for doc in texts]\n",
    "labels = [doc.label for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(label='style', title='Rolex наградит победителей регаты', content='Парусная гонка Giraglia Rolex Cup пройдет в Средиземном море в 64-й раз. Победители соревнования, проводимого с 1953 года Yacht Club Italiano, помимо других призов традиционно получают в подарок часы от швейцарского бренда Rolex. Об этом сообщается в пресс-релизе, поступившем в редакцию «Ленты.ру» в среду, 8 мая. Rolex Yacht-Master 40 Фото: пресс-служба Mercury Соревнования будут проходить с 10 по 18 июня. Первый этап: ночной переход из Сан-Ремо в Сен-Тропе 10-11 июня (дистанция 50 морских миль — около 90 километров). Второй этап: серия прибрежных гонок в бухте Сен-Тропе с 11 по 14 июня. Финальный этап пройдет с 15 по 18 июня: оффшорная гонка по маршруту Сен-Тропе — Генуя (243 морских мили — 450 километров). Маршрут проходит через скалистый остров Джиралья к северу от Корсики и завершается в Генуе.Регата, с 1997 года проходящая при поддержке Rolex, считается одной из самых значительных яхтенных гонок в Средиземноморье. В этом году в ней ожидается участие трех российских экипажей.'),\n",
       " Text(label='sport', title='Матс Сундин стал советником тренера сборной Швеции по хоккею', content='Шведский хоккеист Матс Сундин назначен советником главного тренера сборной Швеции Пера Мортса. Об этом сообщает официальный сайт Федерации хоккея Швеции.Сундин будет консультировать Мортса на протяжении сезона-2012/13 по спортивным вопросам, а также будет курировать младшие сборные страны. Предполагается, что Сундин также войдет в состав тренерского штаба сборной Швеции на чемпионате мира 2013 года, который пройдет в Швеции и Финляндии.Возможно, сотрудничество Сундина с национальной сборной продлится больше предполагаемого времени и он будет работать с командой на Олимпийских играх 2014 года в Сочи.Сам Сундин в составе сборной Швеции победил на Олимпиаде-2006 в Турине. Вместе с национальной командой он выиграл три чемпионата мира (в 1991, 1992 и 1998 годах), а также становился серебряным (в 1990 и 2003 годах) и бронзовым (1994 и 2001 годах) призером мировых первенств.Большую часть карьеры Сундин провел в составе клуба НХЛ \"Торонто Мейпл Лифс\". Также он выступал в \"Квебек Нордикс\" и \"Ванкувер Кэнакс\", а также в шведском \"Юргордене\". На счету Сундина 1349 (564+785) очков в 1346 играх в НХЛ.Сундин ушел из большого спорта в сентябре 2009 года, посетовав на большую физическую и эмоциональную усталость. 12 ноября 2012 года швед будет введен в Зал славы НХЛ.'),\n",
       " Text(label='media', title='Брендом года по версии EFFIE впервые стал город', content='Гран-при конкурса \"Брэнд года/EFFIE\" получил город Казань, сообщает Sostav.ru. Это первый случай, когда главная награда церемонии досталась населенному пункту.Церемония вручения премии состоялась 12 апреля в \"Гостином дворе\". Председателем жюри конкурса был Владимир Филиппов, президент Российской Академии Рекламы. Он и вручил премию представителю Казани, председателю комитета физической культуры и спорта Исполкома Казани Ильгизу Фахриеву.Казань была выбрана лауреатом за успешное продвижение города как спортивной столицы России. Владельцем бренда является казанская мэрия, а агентством по продвижению - компания ЗАО \"Группа Медиа Артс\".Также среди лауреатов премии оказались такие бренды, как водка \"Белочка: я пришла!\", Связной Банк, пиво Efes Pilsener и Redd\\'s и другие марки. Ё-мобиль, продвигаемый бизнесменом Михаилом Прохоровым, был назван лучшим новым проектом.Список лауреатов традиционно формировался по суммарным итогам оценок независимого жюри. В жюри входили рекламные эксперты, представители Ассоциации Коммуникативных Агентств России (АКАР), Международной Рекламной Ассоциации (IAA) и золотые лауреаты предыдущего года.\"Брэнд года/EFFIE\" - престижная премия в области рекламы и маркетинга, она вручается в России с 1998 года. Премия официально представляет в России международную систему EFFIE.В прошлом году гран-при \"Брэнд года/EFFIE\" получили два торговых знака - \"Аэроэкспресс\", отмеченнный, как \"новый товар или услуга\" и Nissan - за наиболее эффективный вклад в долгосрочную стратегию бренда.Казань является одним из самых развитых городов в спортивном плане в России. Дополнительные возможности в развитии спортивной отрасли город приобрел с выбором его в 2008 году в качестве места проведения XXVII Всемирной Летней Универсиады 2013.'),\n",
       " Text(label='economics', title='Цена нефти WTI снизилась после публикации данных о запасах США', content='Цена американской нефти WTI на лондонской бирже ICE снизилась на 1,3 процента до 47,65 доллара за баррель, свидетельствуют данные биржи. Североморская нефть Brent торгуется на уровне 56,78, почти не изменившись к уровню закрытия предыдущего дня. Накануне марка Brent опустилась на 3,7 процента. Причина падения — данные о запасах нефти в США.По данным Минэнерго США, запасы нефти на прошлой неделе в Соединенных Штатах выросли на 4,513 миллиона баррелей — до 448,9 миллиона баррелей. При этом эксперты ожидали увеличения запасов на 4,43 миллиона баррелей. Резервы дистиллятов повысились на 2,527 миллиона баррелей, при том что ожидалось снижение на 2,25 миллиона баррелей. В то же время запасы бензина сократились на 0,187 миллиона баррелей при ожидавшемся сокращении на 1,75 миллиона баррелей.Под влиянием динамики нефтяных цен снизились также российские фондовые индексы. По информации биржи, на момент публикации данных (17:42 мск). Индекс ММВБ снизился на 0,2 процента до 1661,5 пункта. Днем ранее российский индекс превышал 1690 пунктов. Индекс РТС упал до отметки 841,17 пункта на 0,5 процента.'),\n",
       " Text(label='economics', title='Сбербанк распродаст другим банкирам миллиардные долги россиян', content='Сбербанк выставил на продажу долги по 21,4 тысячи договоров на общую сумму в 5,6 миллиарда рублей. Об этом пишет газета \"Коммерсантъ\" со ссылкой на вице-президента Сбербанка Светлану Сагайдак. Просроченную задолженность по кредитам смогут купить только организации, имеющие банковскую лицензию.О том, что Сбербанк намерен выставить на продажу долги россиян на рекордную сумму, стало известно в конце февраля. Сообщалось, что банк выставит на торги задолженность за 10 миллиардов рублей, из которых восемь миллиардов - собственно долги, а остальное - накопившиеся пени и штрафы.До осени 2011 года крупнейший банк России не продавал долгов коллекторам, а работал с подобными организациями на агентских условиях - платил комиссию за взыскание задолженности.В июне Верховный суд России выпустил постановление, признающее незаконным приобретение долгов организациями, не имеющими банковских лицензий. Фактически, суд признал незаконным деятельность коллекторских агентств, приобретающих задолженность россиян.Ранее Высший арбитражный суд подтверждал законность реализации просроченной задолженности, поэтому позиции судебных властей оказались противоречивыми. Тем не менее, многие крупные банки отложили планы по продаже просроченной задолженности. Так, сообщалось, что Юникредитбанк решил пока не продавать долги россиян, а Райффайзенбанк просто их списал. В октябре деловые СМИ писали, что Росбанк намерен продать свое коллекторское агентство.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['парусный',\n",
       "  'гонка',\n",
       "  'giraglia',\n",
       "  'rolex',\n",
       "  'cup',\n",
       "  'пройти',\n",
       "  'средиземный',\n",
       "  'море',\n",
       "  '64',\n",
       "  'й',\n",
       "  'победитель',\n",
       "  'соревнование',\n",
       "  'проводить',\n",
       "  '1953',\n",
       "  'год',\n",
       "  'yacht',\n",
       "  'club',\n",
       "  'italiano',\n",
       "  'помимо',\n",
       "  'приз',\n",
       "  'традиционно',\n",
       "  'получать',\n",
       "  'подарок',\n",
       "  'часы',\n",
       "  'швейцарский',\n",
       "  'бренд',\n",
       "  'rolex',\n",
       "  'это',\n",
       "  'сообщаться',\n",
       "  'пресс',\n",
       "  'релиз',\n",
       "  'поступить',\n",
       "  'редакция',\n",
       "  'лента',\n",
       "  'ру',\n",
       "  'среда',\n",
       "  '8',\n",
       "  'май',\n",
       "  'rolex',\n",
       "  'yacht',\n",
       "  'master',\n",
       "  '40',\n",
       "  'фото',\n",
       "  'пресс',\n",
       "  'служба',\n",
       "  'mercury',\n",
       "  'соревнование',\n",
       "  'проходить',\n",
       "  '10',\n",
       "  '18',\n",
       "  'июнь',\n",
       "  'первый',\n",
       "  'этап',\n",
       "  'ночной',\n",
       "  'переход',\n",
       "  'сан',\n",
       "  'рть',\n",
       "  'сен',\n",
       "  'тропа',\n",
       "  '10',\n",
       "  '11',\n",
       "  'июнь',\n",
       "  'дистанция',\n",
       "  '50',\n",
       "  'морской',\n",
       "  'миля',\n",
       "  'около',\n",
       "  '90',\n",
       "  'километр',\n",
       "  'второй',\n",
       "  'этап',\n",
       "  'серия',\n",
       "  'прибрежный',\n",
       "  'гонка',\n",
       "  'бухта',\n",
       "  'сен',\n",
       "  'тропа',\n",
       "  '11',\n",
       "  '14',\n",
       "  'июнь',\n",
       "  'финальный',\n",
       "  'этап',\n",
       "  'пройти',\n",
       "  '15',\n",
       "  '18',\n",
       "  'июнь',\n",
       "  'оффшорный',\n",
       "  'гонка',\n",
       "  'маршрут',\n",
       "  'сен',\n",
       "  'тропа',\n",
       "  'генуя',\n",
       "  '243',\n",
       "  'морской',\n",
       "  'миля',\n",
       "  '450',\n",
       "  'километр',\n",
       "  'маршрут',\n",
       "  'проходить',\n",
       "  'скалистый',\n",
       "  'остров',\n",
       "  'джиралья',\n",
       "  'север',\n",
       "  'корсика',\n",
       "  'завершаться',\n",
       "  'генуя',\n",
       "  'регата',\n",
       "  '1997',\n",
       "  'год',\n",
       "  'проходить',\n",
       "  'поддержка',\n",
       "  'rolex',\n",
       "  'считаться',\n",
       "  'самый',\n",
       "  'значительный',\n",
       "  'яхтенный',\n",
       "  'гонка',\n",
       "  'средиземноморье',\n",
       "  'это',\n",
       "  'год',\n",
       "  'ожидаться',\n",
       "  'участие',\n",
       "  'российский',\n",
       "  'экипаж'],\n",
       " ['шведский',\n",
       "  'хоккеист',\n",
       "  'матс',\n",
       "  'сундина',\n",
       "  'назначить',\n",
       "  'советник',\n",
       "  'главное',\n",
       "  'тренер',\n",
       "  'сборная',\n",
       "  'швеция',\n",
       "  'перо',\n",
       "  'мортс',\n",
       "  'это',\n",
       "  'сообщать',\n",
       "  'официальный',\n",
       "  'сайт',\n",
       "  'федерация',\n",
       "  'хоккей',\n",
       "  'швеция',\n",
       "  'сундина',\n",
       "  'консультировать',\n",
       "  'мортс',\n",
       "  'протяжение',\n",
       "  'сезон',\n",
       "  '2012',\n",
       "  '13',\n",
       "  'спортивный',\n",
       "  'вопрос',\n",
       "  'также',\n",
       "  'курировать',\n",
       "  'младший',\n",
       "  'сборный',\n",
       "  'страна',\n",
       "  'предполагаться',\n",
       "  'сундина',\n",
       "  'также',\n",
       "  'войти',\n",
       "  'состав',\n",
       "  'тренерский',\n",
       "  'штаб',\n",
       "  'сборная',\n",
       "  'швеция',\n",
       "  'чемпионат',\n",
       "  'мир',\n",
       "  '2013',\n",
       "  'год',\n",
       "  'который',\n",
       "  'пройти',\n",
       "  'швеция',\n",
       "  'финляндия',\n",
       "  'возможно',\n",
       "  'сотрудничество',\n",
       "  'сундина',\n",
       "  'национальный',\n",
       "  'сборная',\n",
       "  'продлиться',\n",
       "  'большой',\n",
       "  'предполагать',\n",
       "  'время',\n",
       "  'работать',\n",
       "  'команда',\n",
       "  'олимпийский',\n",
       "  'игра',\n",
       "  '2014',\n",
       "  'год',\n",
       "  'сочи',\n",
       "  'сундина',\n",
       "  'состав',\n",
       "  'сборная',\n",
       "  'швеция',\n",
       "  'победить',\n",
       "  'олимпиада',\n",
       "  '2006',\n",
       "  'турин',\n",
       "  'вместе',\n",
       "  'национальный',\n",
       "  'команда',\n",
       "  'выиграть',\n",
       "  'чемпионат',\n",
       "  'мир',\n",
       "  '1991',\n",
       "  '1992',\n",
       "  '1998',\n",
       "  'год',\n",
       "  'также',\n",
       "  'становиться',\n",
       "  'серебряный',\n",
       "  '1990',\n",
       "  '2003',\n",
       "  'год',\n",
       "  'бронзовый',\n",
       "  '1994',\n",
       "  '2001',\n",
       "  'год',\n",
       "  'призёр',\n",
       "  'мировой',\n",
       "  'первенство',\n",
       "  'больший',\n",
       "  'часть',\n",
       "  'карьера',\n",
       "  'сундина',\n",
       "  'провести',\n",
       "  'состав',\n",
       "  'клуб',\n",
       "  'нхл',\n",
       "  'торонто',\n",
       "  'мейпл',\n",
       "  'лифс',\n",
       "  'также',\n",
       "  'выступать',\n",
       "  'квебек',\n",
       "  'нордикс',\n",
       "  'ванкувер',\n",
       "  'кэнакс',\n",
       "  'также',\n",
       "  'шведский',\n",
       "  'юргордень',\n",
       "  'счёт',\n",
       "  'сундина',\n",
       "  '1349',\n",
       "  '564',\n",
       "  '785',\n",
       "  'очко',\n",
       "  '1346',\n",
       "  'игра',\n",
       "  'нхл',\n",
       "  'сундина',\n",
       "  'уйти',\n",
       "  'большой',\n",
       "  'спорт',\n",
       "  'сентябрь',\n",
       "  '2009',\n",
       "  'год',\n",
       "  'посетовать',\n",
       "  'больший',\n",
       "  'физический',\n",
       "  'эмоциональный',\n",
       "  'усталость',\n",
       "  '12',\n",
       "  'ноябрь',\n",
       "  '2012',\n",
       "  'год',\n",
       "  'швед',\n",
       "  'ввести',\n",
       "  'зал',\n",
       "  'слава',\n",
       "  'нхл'],\n",
       " ['гран',\n",
       "  'конкурс',\n",
       "  'брэнд',\n",
       "  'год',\n",
       "  'effie',\n",
       "  'получить',\n",
       "  'город',\n",
       "  'казань',\n",
       "  'сообщать',\n",
       "  'sostav',\n",
       "  'ru',\n",
       "  'это',\n",
       "  'первый',\n",
       "  'случай',\n",
       "  'главный',\n",
       "  'награда',\n",
       "  'церемония',\n",
       "  'достаться',\n",
       "  'населить',\n",
       "  'пункт',\n",
       "  'церемония',\n",
       "  'вручение',\n",
       "  'премия',\n",
       "  'состояться',\n",
       "  '12',\n",
       "  'апрель',\n",
       "  'гостиный',\n",
       "  'двор',\n",
       "  'председатель',\n",
       "  'жюри',\n",
       "  'конкурс',\n",
       "  'владимир',\n",
       "  'филипп',\n",
       "  'президент',\n",
       "  'российский',\n",
       "  'академия',\n",
       "  'реклама',\n",
       "  'вручить',\n",
       "  'премия',\n",
       "  'представитель',\n",
       "  'казань',\n",
       "  'председатель',\n",
       "  'комитет',\n",
       "  'физический',\n",
       "  'культура',\n",
       "  'спорт',\n",
       "  'исполком',\n",
       "  'казань',\n",
       "  'ильгиз',\n",
       "  'фахриева',\n",
       "  'казань',\n",
       "  'выбрать',\n",
       "  'лауреат',\n",
       "  'успешный',\n",
       "  'продвижение',\n",
       "  'город',\n",
       "  'спортивный',\n",
       "  'столица',\n",
       "  'россия',\n",
       "  'владелец',\n",
       "  'бренд',\n",
       "  'являться',\n",
       "  'казанский',\n",
       "  'мэрия',\n",
       "  'агентство',\n",
       "  'продвижение',\n",
       "  'компания',\n",
       "  'зао',\n",
       "  'группа',\n",
       "  'медиа',\n",
       "  'артс',\n",
       "  'также',\n",
       "  'среди',\n",
       "  'лауреат',\n",
       "  'премия',\n",
       "  'оказаться',\n",
       "  'бренд',\n",
       "  'водка',\n",
       "  'белочка',\n",
       "  'прийти',\n",
       "  'связный',\n",
       "  'банк',\n",
       "  'пиво',\n",
       "  'efes',\n",
       "  'pilsener',\n",
       "  'redd',\n",
       "  's',\n",
       "  'марка',\n",
       "  'ё',\n",
       "  'мобиль',\n",
       "  'продвигать',\n",
       "  'бизнесмен',\n",
       "  'михаил',\n",
       "  'прохоров',\n",
       "  'назвать',\n",
       "  'хороший',\n",
       "  'новый',\n",
       "  'проект',\n",
       "  'список',\n",
       "  'лауреат',\n",
       "  'традиционно',\n",
       "  'формироваться',\n",
       "  'суммарный',\n",
       "  'итог',\n",
       "  'оценка',\n",
       "  'независимый',\n",
       "  'жюри',\n",
       "  'жюри',\n",
       "  'входить',\n",
       "  'рекламный',\n",
       "  'эксперт',\n",
       "  'представитель',\n",
       "  'ассоциация',\n",
       "  'коммуникативный',\n",
       "  'агентство',\n",
       "  'россия',\n",
       "  'акара',\n",
       "  'международный',\n",
       "  'рекламный',\n",
       "  'ассоциация',\n",
       "  'iaa',\n",
       "  'золотой',\n",
       "  'лауреат',\n",
       "  'предыдущий',\n",
       "  'год',\n",
       "  'брэнд',\n",
       "  'год',\n",
       "  'effie',\n",
       "  'престижный',\n",
       "  'премия',\n",
       "  'область',\n",
       "  'реклама',\n",
       "  'маркетинг',\n",
       "  'вручаться',\n",
       "  'россия',\n",
       "  '1998',\n",
       "  'год',\n",
       "  'премия',\n",
       "  'официально',\n",
       "  'представлять',\n",
       "  'россия',\n",
       "  'международный',\n",
       "  'система',\n",
       "  'effie',\n",
       "  'прошлый',\n",
       "  'год',\n",
       "  'гран',\n",
       "  'брэнд',\n",
       "  'год',\n",
       "  'effie',\n",
       "  'получить',\n",
       "  'торговый',\n",
       "  'знак',\n",
       "  'аэроэкспресс',\n",
       "  'отмеченнный',\n",
       "  'новый',\n",
       "  'товар',\n",
       "  'услуга',\n",
       "  'nissan',\n",
       "  'наиболее',\n",
       "  'эффективный',\n",
       "  'вклад',\n",
       "  'долгосрочный',\n",
       "  'стратегия',\n",
       "  'бренд',\n",
       "  'казань',\n",
       "  'являться',\n",
       "  'самый',\n",
       "  'развитой',\n",
       "  'город',\n",
       "  'спортивный',\n",
       "  'план',\n",
       "  'россия',\n",
       "  'дополнительный',\n",
       "  'возможность',\n",
       "  'развитие',\n",
       "  'спортивный',\n",
       "  'отрасль',\n",
       "  'город',\n",
       "  'приобрести',\n",
       "  'выбор',\n",
       "  '2008',\n",
       "  'год',\n",
       "  'качество',\n",
       "  'место',\n",
       "  'проведение',\n",
       "  'xxvii',\n",
       "  'всемирный',\n",
       "  'летний',\n",
       "  'универсиада',\n",
       "  '2013'],\n",
       " ['цена',\n",
       "  'американский',\n",
       "  'нефть',\n",
       "  'wti',\n",
       "  'лондонский',\n",
       "  'биржа',\n",
       "  'ice',\n",
       "  'снизиться',\n",
       "  '1',\n",
       "  '3',\n",
       "  'процент',\n",
       "  '47',\n",
       "  '65',\n",
       "  'доллар',\n",
       "  'баррель',\n",
       "  'свидетельствовать',\n",
       "  'дать',\n",
       "  'биржа',\n",
       "  'североморский',\n",
       "  'нефть',\n",
       "  'brent',\n",
       "  'торговаться',\n",
       "  'уровень',\n",
       "  '56',\n",
       "  '78',\n",
       "  'измениться',\n",
       "  'уровень',\n",
       "  'закрытие',\n",
       "  'предыдущий',\n",
       "  'день',\n",
       "  'накануне',\n",
       "  'марк',\n",
       "  'brent',\n",
       "  'опуститься',\n",
       "  '3',\n",
       "  '7',\n",
       "  'процент',\n",
       "  'причина',\n",
       "  'падение',\n",
       "  'дать',\n",
       "  'запас',\n",
       "  'нефть',\n",
       "  'сша',\n",
       "  'данные',\n",
       "  'минэнерго',\n",
       "  'сша',\n",
       "  'запас',\n",
       "  'нефть',\n",
       "  'прошлый',\n",
       "  'неделя',\n",
       "  'соединить',\n",
       "  'штат',\n",
       "  'вырасти',\n",
       "  '4',\n",
       "  '513',\n",
       "  'миллион',\n",
       "  'баррель',\n",
       "  '448',\n",
       "  '9',\n",
       "  'миллион',\n",
       "  'баррель',\n",
       "  'это',\n",
       "  'эксперт',\n",
       "  'ожидать',\n",
       "  'увеличение',\n",
       "  'запас',\n",
       "  '4',\n",
       "  '43',\n",
       "  'миллион',\n",
       "  'баррель',\n",
       "  'резерв',\n",
       "  'дистиллят',\n",
       "  'повыситься',\n",
       "  '2',\n",
       "  '527',\n",
       "  'миллион',\n",
       "  'баррель',\n",
       "  'ожидаться',\n",
       "  'снижение',\n",
       "  '2',\n",
       "  '25',\n",
       "  'миллион',\n",
       "  'баррель',\n",
       "  'время',\n",
       "  'запас',\n",
       "  'бензин',\n",
       "  'сократиться',\n",
       "  '0',\n",
       "  '187',\n",
       "  'миллион',\n",
       "  'баррель',\n",
       "  'ожидаться',\n",
       "  'сокращение',\n",
       "  '1',\n",
       "  '75',\n",
       "  'миллион',\n",
       "  'баррель',\n",
       "  'влияние',\n",
       "  'динамика',\n",
       "  'нефтяной',\n",
       "  'цена',\n",
       "  'снизиться',\n",
       "  'также',\n",
       "  'российский',\n",
       "  'фондовый',\n",
       "  'индекс',\n",
       "  'информация',\n",
       "  'биржа',\n",
       "  'момент',\n",
       "  'публикация',\n",
       "  'данные',\n",
       "  '17',\n",
       "  '42',\n",
       "  'мск',\n",
       "  'индекс',\n",
       "  'ммвб',\n",
       "  'снизиться',\n",
       "  '0',\n",
       "  '2',\n",
       "  'процент',\n",
       "  '1661',\n",
       "  '5',\n",
       "  'пункт',\n",
       "  'день',\n",
       "  'ранее',\n",
       "  'российский',\n",
       "  'индекс',\n",
       "  'превышать',\n",
       "  '1690',\n",
       "  'пункт',\n",
       "  'индекс',\n",
       "  'ртс',\n",
       "  'упасть',\n",
       "  'отметка',\n",
       "  '841',\n",
       "  '17',\n",
       "  'пункт',\n",
       "  '0',\n",
       "  '5',\n",
       "  'процент'],\n",
       " ['сбербанк',\n",
       "  'выставить',\n",
       "  'продажа',\n",
       "  'долг',\n",
       "  '21',\n",
       "  '4',\n",
       "  'тысяча',\n",
       "  'договор',\n",
       "  'общий',\n",
       "  'сумма',\n",
       "  '5',\n",
       "  '6',\n",
       "  'миллиард',\n",
       "  'рубль',\n",
       "  'это',\n",
       "  'писать',\n",
       "  'газета',\n",
       "  'коммерсантъ',\n",
       "  'ссылка',\n",
       "  'вица',\n",
       "  'президент',\n",
       "  'сбербанк',\n",
       "  'светлана',\n",
       "  'сагайдак',\n",
       "  'просрочить',\n",
       "  'задолженность',\n",
       "  'кредит',\n",
       "  'смочь',\n",
       "  'купить',\n",
       "  'организация',\n",
       "  'иметь',\n",
       "  'банковский',\n",
       "  'лицензия',\n",
       "  'сбербанк',\n",
       "  'намеренный',\n",
       "  'выставить',\n",
       "  'продажа',\n",
       "  'долг',\n",
       "  'россиянин',\n",
       "  'рекордный',\n",
       "  'сумма',\n",
       "  'стать',\n",
       "  'известно',\n",
       "  'конец',\n",
       "  'февраль',\n",
       "  'сообщаться',\n",
       "  'банк',\n",
       "  'выставить',\n",
       "  'торг',\n",
       "  'задолженность',\n",
       "  '10',\n",
       "  'миллиард',\n",
       "  'рубль',\n",
       "  'который',\n",
       "  'восемь',\n",
       "  'миллиард',\n",
       "  'собственно',\n",
       "  'долг',\n",
       "  'остальной',\n",
       "  'накопиться',\n",
       "  'пеня',\n",
       "  'штраф',\n",
       "  'осень',\n",
       "  '2011',\n",
       "  'год',\n",
       "  'крупный',\n",
       "  'банк',\n",
       "  'россия',\n",
       "  'продавать',\n",
       "  'долг',\n",
       "  'коллектор',\n",
       "  'работать',\n",
       "  'подобный',\n",
       "  'организация',\n",
       "  'агентский',\n",
       "  'условие',\n",
       "  'платить',\n",
       "  'комиссия',\n",
       "  'взыскание',\n",
       "  'задолженность',\n",
       "  'июнь',\n",
       "  'верховный',\n",
       "  'суд',\n",
       "  'россия',\n",
       "  'выпустить',\n",
       "  'постановление',\n",
       "  'признавать',\n",
       "  'незаконный',\n",
       "  'приобретение',\n",
       "  'долг',\n",
       "  'организация',\n",
       "  'иметь',\n",
       "  'банковский',\n",
       "  'лицензия',\n",
       "  'фактически',\n",
       "  'суд',\n",
       "  'признать',\n",
       "  'незаконный',\n",
       "  'деятельность',\n",
       "  'коллекторский',\n",
       "  'агентство',\n",
       "  'приобретать',\n",
       "  'задолженность',\n",
       "  'россиянин',\n",
       "  'ранее',\n",
       "  'высокий',\n",
       "  'арбитражный',\n",
       "  'суд',\n",
       "  'подтверждать',\n",
       "  'законность',\n",
       "  'реализация',\n",
       "  'просрочить',\n",
       "  'задолженность',\n",
       "  'поэтому',\n",
       "  'позиция',\n",
       "  'судебный',\n",
       "  'власть',\n",
       "  'оказаться',\n",
       "  'противоречивый',\n",
       "  'менее',\n",
       "  'многие',\n",
       "  'крупный',\n",
       "  'банк',\n",
       "  'отложить',\n",
       "  'план',\n",
       "  'продажа',\n",
       "  'просрочить',\n",
       "  'задолженность',\n",
       "  'сообщаться',\n",
       "  'юникредитбанк',\n",
       "  'решить',\n",
       "  'пока',\n",
       "  'продавать',\n",
       "  'долг',\n",
       "  'россиянин',\n",
       "  'райффайзенбанк',\n",
       "  'просто',\n",
       "  'списать',\n",
       "  'октябрь',\n",
       "  'деловой',\n",
       "  'сми',\n",
       "  'писать',\n",
       "  'росбанк',\n",
       "  'намеренный',\n",
       "  'продать',\n",
       "  'свой',\n",
       "  'коллекторский',\n",
       "  'агентство']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['style', 'sport', 'media', 'economics', 'economics']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Векторное представление слов\n",
    "\n",
    "Обучим Word2Vec и FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = Word2Vec(sentences=corpus)\n",
    "# сохраняем модель\n",
    "w2v.save('w2v_default.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = FastText(sentences=corpus)\n",
    "ft.save(\"fs_default.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('итар', 0.6321862936019897),\n",
       " ('прайма', 0.5768018960952759),\n",
       " ('бёлтый', 0.5752525925636292),\n",
       " ('интерфакс', 0.5749506950378418),\n",
       " ('тасс', 0.5697027444839478),\n",
       " ('ренхап', 0.5616961717605591),\n",
       " ('service', 0.5563392639160156),\n",
       " ('агентство', 0.550072968006134),\n",
       " ('корреспондент', 0.5459086894989014),\n",
       " ('радиостанция', 0.539406955242157)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar(\"новость\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('новостной', 0.8780274391174316),\n",
       " ('сонливость', 0.84711754322052),\n",
       " ('новосельцев', 0.8130514025688171),\n",
       " ('ведомость', 0.8108958601951599),\n",
       " ('цитируемость', 0.7947829365730286),\n",
       " ('справедливость', 0.7823488116264343),\n",
       " ('интерфакс', 0.7537603378295898),\n",
       " ('глупость', 0.7456846833229065),\n",
       " ('несправедливость', 0.7405885457992554),\n",
       " ('хвост', 0.7292425632476807)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.wv.most_similar(\"новость\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим еще несколько моделей (будем варьировать параметры), чтобы в дальнейшем сравнить результаты для разных векторных представлений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# попробуем skip-gram, т.к. наш набор данных небольшой и будет полезно захватывать редкие слова\n",
    "w2v_skip_gram = Word2Vec(sentences=corpus,\n",
    "                         vector_size=70,\n",
    "                         sg=1,\n",
    "                         min_count=2)\n",
    "w2v_skip_gram.save(\"w2v_skipgram.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавим иерархический softmax\n",
    "w2v_hs = Word2Vec(sentences=corpus,\n",
    "                  vector_size=70,\n",
    "                  hs=1)\n",
    "w2v_hs.save(\"w2v_hs.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Отобразим каждый документ в вектор"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, FastText\n",
    "\n",
    "model_w2v = Word2Vec.load(\"w2v_default.model\")\n",
    "model_w2v_hs = Word2Vec.load(\"w2v_hs.model\")\n",
    "model_w2v_skipgram = Word2Vec.load(\"w2v_skipgram.model\")\n",
    "model_ft = FastText.load(\"fs_default.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью обученных моделей векторного представления отобразим каждый документ в вектор, усреднив все вектора для слов документа. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def document_to_vector_avg(doc, model):\n",
    "    tokens = [token for token in doc if token in model.wv.index_to_key]\n",
    "    if len(tokens) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    else:\n",
    "        return np.mean(model.wv[tokens], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Альтернатива: сумма\n",
    "\n",
    "По сути, не должно быть сильных различий с средним, т.к. все равно является похожей линейной комбинацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_to_vector_sum(doc, model):\n",
    "    tokens = [token for token in doc if token in model.wv.index_to_key]\n",
    "    if len(tokens) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    else:\n",
    "        return np.sum(model.wv[tokens], axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Альтернатива: медиана\n",
    "\n",
    "Медиана устойчива к выбросам, хотя мы старались от них уйти еще в момент обучения моделей векторного представления слов. Однако медиана может дать интересный результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_to_vector_median(doc, model):\n",
    "    tokens = [token for token in doc if token in model.wv.index_to_key]\n",
    "    if len(tokens) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    else:\n",
    "        return np.median(model.wv[tokens], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Альтернатива: взвешенное средение\n",
    "\n",
    "Попробуем использовать дополнительную информацию о токенах, чтобы каждый word embedding [имел определенный вес в усреднении](https://www.kaggle.com/code/sahib12/document-embedding-techniques?scriptVersionId=31484359&cellId=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.2, min_df=10).fit([' '.join(text) for text in corpus])\n",
    "feature_names = list(vectorizer.get_feature_names_out())\n",
    "feature_names_dict = {word: idx for idx, word in enumerate(feature_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_matrix = vectorizer.transform([' '.join(text) for text in corpus])\n",
    "\n",
    "def document_to_vector_weighted_avg(doc, idx_doc, model):\n",
    "    tokens = [token for token in doc if token in model.wv.index_to_key\n",
    "                                     and token in feature_names]\n",
    "    doc_vector = np.sum([model.wv[token] * tf_idf_matrix[idx_doc, feature_names_dict[token]] for token in tokens],\n",
    "                        axis=0)\n",
    "    \n",
    "    if len(tokens) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    else:\n",
    "        return doc_vector / len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Обучение и тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "models = [model_w2v, model_w2v_hs, model_w2v_skipgram, model_ft]\n",
    "\n",
    "def train_test_process(model, doc_to_vec):\n",
    "    X = np.array([doc_to_vec(text, model) for text in corpus])\n",
    "    y = labels\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=19)\n",
    "    \n",
    "    # обучим SVM\n",
    "    svm_classifier = SVC(kernel='linear', random_state=19)\n",
    "    svm_classifier.fit(X_train, y_train)\n",
    "    svm_predictions = svm_classifier.predict(X_test)\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, svm_predictions):.4f}\")\n",
    "    print(f\"F1: {f1_score(y_test, svm_predictions, average='weighted'):.4f}\")\n",
    "\n",
    "    # # обучим RF\n",
    "    # rf_classifier = RandomForestClassifier(n_estimators=70, random_state=19)\n",
    "    # rf_classifier.fit(X_train, y_train)\n",
    "    # rf_predictions = rf_classifier.predict(X_test)\n",
    "    # print(f\"Accuracy: {accuracy_score(y_test, rf_predictions):.4f}\")\n",
    "    # print(f\"F1: {f1_score(y_test, rf_predictions, average='weighted'):.4f}\")\n",
    "\n",
    "def train_test_process_advanced(model):\n",
    "    X = np.array([document_to_vector_weighted_avg(corpus[i], i, model) for i in range(10_000)]) #len(corpus)\n",
    "    y = labels\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=19)\n",
    "    \n",
    "    # обучим SVM\n",
    "    svm_classifier = SVC(kernel='linear', random_state=19)\n",
    "    svm_classifier.fit(X_train, y_train)\n",
    "    svm_predictions = svm_classifier.predict(X_test)\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, svm_predictions):.4f}\")\n",
    "    print(f\"F1: {f1_score(y_test, svm_predictions, average='weighted'):.4f}\")\n",
    "\n",
    "    # # обучим RF\n",
    "    # rf_classifier = RandomForestClassifier(n_estimators=70, random_state=19)\n",
    "    # rf_classifier.fit(X_train, y_train)\n",
    "    # rf_predictions = rf_classifier.predict(X_test)\n",
    "    # print(f\"Accuracy: {accuracy_score(y_test, rf_predictions):.4f}\")\n",
    "    # print(f\"F1: {f1_score(y_test, rf_predictions, average='weighted'):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подход с усреднением векторов слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / Word2Vec<vocab=21225, vector_size=100, alpha=0.025>\n",
      "Accuracy: 0.8110\n",
      "F1: 0.8017\n",
      "\n",
      "2 / Word2Vec<vocab=21225, vector_size=70, alpha=0.025>\n",
      "Accuracy: 0.8360\n",
      "F1: 0.8318\n",
      "\n",
      "3 / Word2Vec<vocab=39927, vector_size=70, alpha=0.025>\n",
      "Accuracy: 0.8265\n",
      "F1: 0.8134\n",
      "\n",
      "4 / FastText<vocab=21225, vector_size=100, alpha=0.025>\n",
      "Accuracy: 0.7805\n",
      "F1: 0.7674\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, model in enumerate(models):\n",
    "    print(f\"{i+1} / {model}\")\n",
    "    train_test_process(model, document_to_vector_avg)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучше всех себя в данном случае показала модель `Word2Vec` с применением иерархического softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Альтернатива с суммой векторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / Word2Vec<vocab=21225, vector_size=100, alpha=0.025>\n",
      "Accuracy: 0.8040\n",
      "F1: 0.8037\n",
      "\n",
      "2 / Word2Vec<vocab=21225, vector_size=70, alpha=0.025>\n",
      "Accuracy: 0.8180\n",
      "F1: 0.8161\n",
      "\n",
      "3 / Word2Vec<vocab=39927, vector_size=70, alpha=0.025>\n",
      "Accuracy: 0.8230\n",
      "F1: 0.8222\n",
      "\n",
      "4 / FastText<vocab=21225, vector_size=100, alpha=0.025>\n",
      "Accuracy: 0.7970\n",
      "F1: 0.7957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, model in enumerate(models):\n",
    "    print(f\"{i+1} / {model}\")\n",
    "    train_test_process(model, document_to_vector_sum)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Альтернатива с медианой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / Word2Vec<vocab=21225, vector_size=100, alpha=0.025>\n",
      "Accuracy: 0.7985\n",
      "F1: 0.7890\n",
      "\n",
      "2 / Word2Vec<vocab=21225, vector_size=70, alpha=0.025>\n",
      "Accuracy: 0.8150\n",
      "F1: 0.8108\n",
      "\n",
      "3 / Word2Vec<vocab=39927, vector_size=70, alpha=0.025>\n",
      "Accuracy: 0.8150\n",
      "F1: 0.8044\n",
      "\n",
      "4 / FastText<vocab=21225, vector_size=100, alpha=0.025>\n",
      "Accuracy: 0.7860\n",
      "F1: 0.7795\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, model in enumerate(models):\n",
    "    print(f\"{i+1} / {model}\")\n",
    "    train_test_process(model, document_to_vector_median)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Альтернативный подход с взвешенным усреднением"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / Word2Vec<vocab=21225, vector_size=100, alpha=0.025>\n",
      "Accuracy: 0.7580\n",
      "F1: 0.7348\n",
      "\n",
      "2 / Word2Vec<vocab=21225, vector_size=70, alpha=0.025>\n",
      "Accuracy: 0.7945\n",
      "F1: 0.7757\n",
      "\n",
      "3 / Word2Vec<vocab=39927, vector_size=70, alpha=0.025>\n",
      "Accuracy: 0.7710\n",
      "F1: 0.7439\n",
      "\n",
      "4 / FastText<vocab=21225, vector_size=100, alpha=0.025>\n",
      "Accuracy: 0.7340\n",
      "F1: 0.7104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, model in enumerate(models):\n",
    "    print(f\"{i+1} / {model}\")\n",
    "    train_test_process_advanced(model)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* С помощью `gensim.FastText` и `gensim.Word2Vec` обучили 4 модели на предложенном корпусе текстов и получили векторное представление каждого слова в корпусе\n",
    "* Для формирования векторного представления документов попробовали 4 метода: усреднение/сумма/медиана/взвешенное (с помощью tf-idf) усреднение word embeddings\n",
    "* Лучшим сочетание оказалось **обучение Word2Vec (skip-gram) с применение иерархического softmax** и **отображение документа в вектор с помощью простого усреднения**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
