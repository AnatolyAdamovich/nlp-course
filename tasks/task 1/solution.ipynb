{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –î–∞–Ω–Ω—ã–µ\n",
    "\n",
    "–ü—Ä–æ—á–∏—Ç–∞–µ–º —Ñ–∞–π–ª –∏ –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Ç–µ–∫—Å—Ç—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ffrankusha/study/university/nlp-course/tasks/task 1\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "style\tRolex –Ω–∞–≥—Ä–∞–¥–∏—Ç –ø–æ–±–µ–¥–∏—Ç–µ–ª–µ–π —Ä–µ–≥–∞—Ç—ã\t–ü–∞—Ä—É—Å–Ω–∞—è –≥–æ–Ω–∫–∞ Giraglia Rolex Cup –ø—Ä–æ–π–¥–µ—Ç –≤ –°—Ä–µ–¥–∏–∑–µ–º–Ω–æ–º –º–æ—Ä–µ –≤ 64-–π —Ä–∞–∑. –ü–æ–±–µ–¥–∏—Ç–µ–ª–∏ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è, –ø—Ä–æ–≤–æ–¥–∏–º–æ–≥–æ —Å 1953 –≥–æ–¥–∞ Yacht Club Italiano, –ø–æ–º–∏–º–æ –¥—Ä—É–≥–∏—Ö –ø—Ä–∏–∑–æ–≤ —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω–æ –ø–æ–ª—É—á–∞—é—Ç –≤ –ø–æ–¥–∞—Ä–æ–∫ —á–∞—Å—ã –æ—Ç —à–≤–µ–π—Ü–∞—Ä—Å–∫–æ–≥–æ –±—Ä–µ–Ω–¥–∞ Rolex. –û–± —ç—Ç–æ–º —Å–æ–æ–±—â–∞–µ—Ç—Å—è –≤ –ø—Ä–µ—Å—Å-—Ä–µ–ª–∏–∑–µ, –ø–æ—Å—Ç—É–ø–∏–≤—à–µ–º –≤ —Ä–µ–¥–∞–∫—Ü–∏—é ¬´–õ–µ–Ω—Ç—ã.—Ä—É¬ª –≤ —Å—Ä–µ–¥—É, 8 –º–∞—è. Rolex Yacht-Master 40 –§–æ—Ç–æ: –ø—Ä–µ—Å—Å-—Å–ª—É–∂–±–∞ Mercury –°–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è –±—É–¥—É—Ç –ø—Ä–æ—Ö–æ–¥–∏—Ç—å —Å 10 –ø–æ 18 –∏—é–Ω—è. –ü–µ—Ä–≤—ã–π —ç—Ç–∞–ø: –Ω–æ—á–Ω–æ–π –ø–µ—Ä–µ—Ö–æ–¥ –∏–∑ –°–∞–Ω-–†–µ–º–æ –≤ –°–µ–Ω-–¢—Ä–æ–ø–µ 10-11 –∏—é–Ω—è (–¥–∏—Å—Ç–∞–Ω—Ü–∏—è 50 –º–æ—Ä—Å–∫–∏—Ö –º–∏–ª—å ‚Äî –æ–∫–æ–ª–æ 90 –∫–∏–ª–æ–º–µ—Ç—Ä–æ–≤). –í—Ç–æ—Ä–æ–π —ç—Ç–∞–ø: —Å–µ—Ä–∏—è –ø—Ä–∏–±—Ä–µ–∂–Ω—ã—Ö –≥–æ–Ω–æ–∫ –≤ –±—É—Ö—Ç–µ –°–µ–Ω-–¢—Ä–æ–ø–µ —Å 11 –ø–æ 14 –∏—é–Ω—è. –§–∏–Ω–∞–ª—å–Ω—ã–π —ç—Ç–∞–ø –ø—Ä–æ–π–¥–µ—Ç —Å 15 –ø–æ 18 –∏—é–Ω—è: –æ—Ñ—Ñ—à–æ—Ä–Ω–∞—è –≥–æ–Ω–∫–∞ –ø–æ –º–∞—Ä—à—Ä—É—Ç—É –°–µ–Ω-–¢—Ä–æ–ø–µ ‚Äî –ì–µ–Ω—É—è (243 –º–æ—Ä—Å–∫–∏—Ö –º–∏–ª–∏ ‚Äî 450 –∫–∏–ª–æ–º–µ—Ç—Ä–æ–≤). –ú–∞—Ä—à—Ä—É—Ç –ø—Ä–æ—Ö–æ–¥–∏—Ç —á–µ—Ä–µ–∑ —Å–∫–∞–ª–∏—Å—Ç—ã–π –æ—Å—Ç—Ä–æ–≤ –î–∂–∏—Ä–∞–ª—å—è –∫ —Å–µ–≤–µ—Ä—É –æ—Ç –ö–æ—Ä—Å–∏–∫–∏ –∏ –∑–∞–≤–µ—Ä—à–∞–µ—Ç—Å—è –≤ –ì–µ–Ω—É–µ.–†–µ–≥–∞—Ç–∞, —Å 1997 –≥–æ–¥–∞ –ø—Ä–æ—Ö–æ–¥—è—â–∞—è –ø—Ä–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–µ Rolex, —Å—á–∏—Ç–∞–µ—Ç—Å—è –æ–¥–Ω–æ–π –∏–∑ —Å–∞–º—ã—Ö –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã—Ö —è—Ö—Ç–µ–Ω–Ω—ã—Ö –≥–æ–Ω–æ–∫ –≤ –°—Ä–µ–¥–∏–∑–µ–º–Ω–æ–º–æ—Ä—å–µ. –í —ç—Ç–æ–º –≥–æ–¥—É –≤ –Ω–µ–π –æ–∂–∏–¥–∞–µ—Ç—Å—è —É—á–∞—Å—Ç–∏–µ —Ç—Ä–µ—Ö —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö —ç–∫–∏–ø–∞–∂–µ–π.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "\n",
    "filepath = '../../data/news.txt.gz'\n",
    "\n",
    "with gzip.open(filepath, 'rt', encoding='utf-8') as f:\n",
    "    content = f.readline()\n",
    "    \n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–∞–Ω–Ω—ã–µ –∏–º–µ—é—Ç —Ñ–æ—Ä–º–∞—Ç `<tag>  <title>  <content>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "\n",
    "\n",
    "# print(len(content))\n",
    "\n",
    "# memory_size = sys.getsizeof(content)\n",
    "# # –≤ –ú–ë\n",
    "# memory_size / (1024 * 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>style</td>\n",
       "      <td>Rolex –Ω–∞–≥—Ä–∞–¥–∏—Ç –ø–æ–±–µ–¥–∏—Ç–µ–ª–µ–π —Ä–µ–≥–∞—Ç—ã</td>\n",
       "      <td>–ü–∞—Ä—É—Å–Ω–∞—è –≥–æ–Ω–∫–∞ Giraglia Rolex Cup –ø—Ä–æ–π–¥–µ—Ç –≤ –°—Ä...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sport</td>\n",
       "      <td>–ú–∞—Ç—Å –°—É–Ω–¥–∏–Ω —Å—Ç–∞–ª —Å–æ–≤–µ—Ç–Ω–∏–∫–æ–º —Ç—Ä–µ–Ω–µ—Ä–∞ —Å–±–æ—Ä–Ω–æ–π –®–≤...</td>\n",
       "      <td>–®–≤–µ–¥—Å–∫–∏–π —Ö–æ–∫–∫–µ–∏—Å—Ç –ú–∞—Ç—Å –°—É–Ω–¥–∏–Ω –Ω–∞–∑–Ω–∞—á–µ–Ω —Å–æ–≤–µ—Ç–Ω–∏...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>media</td>\n",
       "      <td>–ë—Ä–µ–Ω–¥–æ–º –≥–æ–¥–∞ –ø–æ –≤–µ—Ä—Å–∏–∏ EFFIE –≤–ø–µ—Ä–≤—ã–µ —Å—Ç–∞–ª –≥–æ—Ä–æ–¥</td>\n",
       "      <td>–ì—Ä–∞–Ω-–ø—Ä–∏ –∫–æ–Ω–∫—É—Ä—Å–∞ \"–ë—Ä—ç–Ω–¥ –≥–æ–¥–∞/EFFIE\" –ø–æ–ª—É—á–∏–ª –≥...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tag                                              title  \\\n",
       "0  style                  Rolex –Ω–∞–≥—Ä–∞–¥–∏—Ç –ø–æ–±–µ–¥–∏—Ç–µ–ª–µ–π —Ä–µ–≥–∞—Ç—ã   \n",
       "1  sport  –ú–∞—Ç—Å –°—É–Ω–¥–∏–Ω —Å—Ç–∞–ª —Å–æ–≤–µ—Ç–Ω–∏–∫–æ–º —Ç—Ä–µ–Ω–µ—Ä–∞ —Å–±–æ—Ä–Ω–æ–π –®–≤...   \n",
       "2  media    –ë—Ä–µ–Ω–¥–æ–º –≥–æ–¥–∞ –ø–æ –≤–µ—Ä—Å–∏–∏ EFFIE –≤–ø–µ—Ä–≤—ã–µ —Å—Ç–∞–ª –≥–æ—Ä–æ–¥   \n",
       "\n",
       "                                             content  \n",
       "0  –ü–∞—Ä—É—Å–Ω–∞—è –≥–æ–Ω–∫–∞ Giraglia Rolex Cup –ø—Ä–æ–π–¥–µ—Ç –≤ –°—Ä...  \n",
       "1  –®–≤–µ–¥—Å–∫–∏–π —Ö–æ–∫–∫–µ–∏—Å—Ç –ú–∞—Ç—Å –°—É–Ω–¥–∏–Ω –Ω–∞–∑–Ω–∞—á–µ–Ω —Å–æ–≤–µ—Ç–Ω–∏...  \n",
       "2  –ì—Ä–∞–Ω-–ø—Ä–∏ –∫–æ–Ω–∫—É—Ä—Å–∞ \"–ë—Ä—ç–Ω–¥ –≥–æ–¥–∞/EFFIE\" –ø–æ–ª—É—á–∏–ª –≥...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(filepath,\n",
    "                   sep='\\t',\n",
    "                   header=None)\n",
    "data.columns = ['tag', 'title', 'content']\n",
    "\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>10</td>\n",
       "      <td>9995</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>media</td>\n",
       "      <td>–¶–ë –æ—Ç–æ–∑–≤–∞–ª –ª–∏—Ü–µ–Ω–∑–∏–∏ —É –¥–≤—É—Ö –±–∞–Ω–∫–æ–≤</td>\n",
       "      <td>–°–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –Ω–∞–∑–Ω–∞—á–∏–ª–∏ —Å—É–¥–µ–±–Ω–æ-–ø—Å–∏—Ö–∏–∞—Ç—Ä–∏—á–µ—Å–∫—É—é ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1476</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tag                              title  \\\n",
       "count   10000                              10000   \n",
       "unique     10                               9995   \n",
       "top     media  –¶–ë –æ—Ç–æ–∑–≤–∞–ª –ª–∏—Ü–µ–Ω–∑–∏–∏ —É –¥–≤—É—Ö –±–∞–Ω–∫–æ–≤   \n",
       "freq     1476                                  3   \n",
       "\n",
       "                                                  content  \n",
       "count                                               10000  \n",
       "unique                                              10000  \n",
       "top     –°–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –Ω–∞–∑–Ω–∞—á–∏–ª–∏ —Å—É–¥–µ–±–Ω–æ-–ø—Å–∏—Ö–∏–∞—Ç—Ä–∏—á–µ—Å–∫—É—é ...  \n",
       "freq                                                    1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –û–ø–∏—Å–∞–Ω–∏–µ facts, rules\n",
    "\n",
    "–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –∏–∑–≤–ª–µ–∫–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –≤–∏–¥–∞: \n",
    "* —á–µ–ª–æ–≤–µ–∫ -> —Ä–æ–¥–∏–ª—Å—è (—Ä–æ–¥–∏–ª–æ—Å—å) –≤ ... –≥–æ–¥—É\n",
    "* —á–µ–ª–æ–≤–µ–∫ -> —Ä–æ–¥–∏–ª—Å—è (—Ä–æ–¥–∏–ª–æ—Å—å) –≤ –≥–æ—Ä–æ–¥–µ/—Å—Ç—Ä–∞–Ω–µ ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yargy import Parser, rule, and_, or_\n",
    "from yargy.predicates import gram, is_capitalized, dictionary, normalized, gte, lte, caseless\n",
    "from yargy.pipelines import morph_pipeline\n",
    "from yargy.interpretation import fact\n",
    "from yargy.relations import gnc_relation\n",
    "\n",
    "gnc = gnc_relation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –¶–µ–ª–µ–≤–æ–π —Ñ–∞–∫—Ç\n",
    "Entry = fact(\n",
    "    'Entry',\n",
    "    ['name', 'birth_date', 'birth_place']\n",
    ")\n",
    "\n",
    "# –ß–µ–ª–æ–≤–µ–∫ (–∏–º—è)\n",
    "Person = fact(\n",
    "    \"Person\",\n",
    "    [\"first_name\", \"last_name\"]\n",
    ")\n",
    "\n",
    "# –î–∞—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è\n",
    "BirthDate = fact(\n",
    "    'Date',\n",
    "    ['year', 'month', 'day']\n",
    ")\n",
    "\n",
    "# –ú–µ—Å—Ç–æ —Ä–æ–∂–¥–µ–Ω–∏—è\n",
    "BirthPlace = fact(\n",
    "    'Place',\n",
    "    ['name']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü—Ä–∞–≤–∏–ª–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–º–µ–Ω–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAME = rule(\n",
    "#     is_capitalized().match(gnc).interpretation(Person.first_name.inflected()).optional(),\n",
    "#     is_capitalized().match(gnc).interpretation(Person.last_name.inflected()),\n",
    "# ).interpretation(\n",
    "#     Entry.name\n",
    "# )\n",
    "\n",
    "# –±–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–æ–µ\n",
    "NAME_FIRST_LAST = rule(\n",
    "    gram(\"Name\").match(gnc).interpretation(Person.first_name.inflected()),\n",
    "    gram(\"Surn\").optional().match(gnc).interpretation(Person.last_name.inflected())\n",
    ")\n",
    "\n",
    "NAME_LAST_FIRST = rule(\n",
    "    gram(\"Surn\").optional().match(gnc).interpretation(Person.last_name.inflected()),\n",
    "    gram(\"Name\").match(gnc).interpretation(Person.first_name.inflected())\n",
    ")\n",
    "\n",
    "# –≤–∏–¥–∏–º–æ –ø—Ä–∏–¥–µ—Ç—Å—è –¥–æ–±–∞–≤–∏—Ç—å\n",
    "NAME_COMMON = rule(\n",
    "    is_capitalized().match(gnc).interpretation(Person.last_name.inflected()).optional(),\n",
    "    gram(\"Name\").match(gnc).interpretation(Person.first_name.inflected()),\n",
    ")\n",
    "NAME_COMMON_REVERSE = rule(\n",
    "    gram(\"Name\").match(gnc).interpretation(Person.first_name.inflected()),\n",
    "    is_capitalized().match(gnc).interpretation(Person.last_name.inflected()).optional()\n",
    ")\n",
    "\n",
    "\n",
    "NAME = or_(\n",
    "    NAME_FIRST_LAST,\n",
    "    NAME_LAST_FIRST,\n",
    "    NAME_COMMON,\n",
    "    NAME_COMMON_REVERSE\n",
    ").interpretation(\n",
    "    Person\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['–ò–≤–∞–Ω']\n",
      "Person(first_name='–∏–≤–∞–Ω', last_name=None)\n",
      "['–ò–≥–æ—Ä—å', '–í–ª–∞–¥–∏–º–∏—Ä–æ–≤']\n",
      "Person(first_name='–∏–≥–æ—Ä—å', last_name='–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤')\n",
      "['–ò–≤–∞–Ω–æ–≤', '–ü–µ—Ç—è']\n",
      "Person(first_name='–ø–µ—Ç—è', last_name='–∏–≤–∞–Ω–æ–≤')\n"
     ]
    }
   ],
   "source": [
    "# –ø—Ä–æ–≤–µ—Ä–∫–∞\n",
    "parser_name = Parser(NAME)\n",
    "\n",
    "text = \"–ò–≤–∞–Ω –∏–≥—Ä–∞–ª –≤ —Ñ—É—Ç–±–æ–ª. –ò–≥–æ—Ä—å –í–ª–∞–¥–∏–º–∏—Ä–æ–≤ –ø—Ä–∏—à–µ–ª –¥–æ–º–æ–π. –ò–≤–∞–Ω–æ–≤ –ü–µ—Ç—è —Ä–æ–¥–∏–ª—Å—è –≤ 2001 –≥–æ–¥—É.\"\n",
    "\n",
    "for match in parser_name.findall(text):\n",
    "    print([_.value for _ in match.tokens])\n",
    "    print(match.fact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü—Ä–∞–≤–∏–ª–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞—Ç—ã —Ä–æ–∂–¥–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –º–µ—Å—è—Ü –º–æ–∂–µ—Ç –±—ã—Ç—å –∑–∞–¥–∞–Ω –≤ —Å–ª–æ–≤–µ—Å–Ω–æ–º –∏ —á–∏—Å–ª–æ–≤–æ–º –≤–∏–¥–µ\n",
    "months_names = {\n",
    "    '—è–Ω–≤–∞—Ä—å': 1,\n",
    "    '—Ñ–µ–≤—Ä–∞–ª—å': 2,\n",
    "    '–º–∞—Ä—Ç': 3,\n",
    "    '–∞–ø—Ä–µ–ª—å': 4,\n",
    "    '–º–∞–π': 5,\n",
    "    '–∏—é–Ω—å': 6,\n",
    "    '–∏—é–ª—å': 7,\n",
    "    '–∞–≤–≥—É—Å—Ç': 8,\n",
    "    '—Å–µ–Ω—Ç—è–±—Ä—å': 9,\n",
    "    '–æ–∫—Ç—è–±—Ä—å': 10,\n",
    "    '–Ω–æ—è–±—Ä—å': 11,\n",
    "    '–¥–µ–∫–∞–±—Ä—å': 12\n",
    "}\n",
    "\n",
    "MONTH_NAME = dictionary(\n",
    "    months_names\n",
    ").interpretation(\n",
    "    BirthDate.month.normalized().custom(months_names.get)\n",
    ")\n",
    "\n",
    "MONTH_NUMBER = and_(\n",
    "    gte(1),\n",
    "    lte(12)\n",
    ").interpretation(\n",
    "    BirthDate.month.custom(int)\n",
    ")\n",
    "\n",
    "# –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª\n",
    "MONTH = or_(\n",
    "    MONTH_NAME,\n",
    "    MONTH_NUMBER\n",
    ")\n",
    "\n",
    "# –ø—Ä–∞–≤–∏–ª–æ –¥–ª—è –¥–Ω—è\n",
    "DAY = and_(\n",
    "    gte(1),\n",
    "    lte(31)\n",
    ").interpretation(\n",
    "    BirthDate.day.custom(int)\n",
    ")\n",
    "\n",
    "# –ø—Ä–∞–≤–∏–ª–æ –¥–ª—è –≥–æ–¥–∞\n",
    "YEAR = rule(\n",
    "    and_(\n",
    "        gte(1000),\n",
    "        lte(2025)\n",
    "    ).interpretation(\n",
    "    BirthDate.year.custom(int)\n",
    "    ),\n",
    "    normalized(\"–≥–æ–¥\").optional(),\n",
    "    rule(caseless(\"–≥\"), \".\").optional()\n",
    ")\n",
    "\n",
    "DATE_YEAR = rule(\n",
    "    DAY.optional(),\n",
    "    dictionary({'.', '-', '/'}).optional(),\n",
    "    MONTH.optional(),\n",
    "    dictionary({'.', '-', '/'}).optional(),\n",
    "    YEAR\n",
    ")\n",
    "DATE_DAY_MONTH = rule(\n",
    "    DAY,\n",
    "    dictionary({'.', '-', '/'}).optional(),\n",
    "    MONTH,\n",
    "    YEAR.optional()\n",
    ")\n",
    "DATE = or_(\n",
    "        DATE_DAY_MONTH,\n",
    "        DATE_YEAR  \n",
    ")\n",
    "\n",
    "BIRTH_DATE = rule(\n",
    "    dictionary({\"–≤\"}).optional(),\n",
    "    gram('ADJF').repeatable().optional(), # –Ω–∞ —Å–ª—É—á–∞–π –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã—Ö\n",
    "    DATE\n",
    ").interpretation(\n",
    "        BirthDate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['–≤', '10', '-', '05', '-', '1980']\n",
      "Date(year=1980, month=5, day=10)\n",
      "['20', '/', '04', '/', '1990']\n",
      "Date(year=1990, month=4, day=20)\n",
      "['–≤', '2001', '–≥–æ–¥—É']\n",
      "Date(year=2001, month=None, day=None)\n",
      "['21', '–æ–∫—Ç—è–±—Ä—è']\n",
      "Date(year=None, month=10, day=21)\n",
      "['–≤', '2000', '–≥', '.']\n",
      "Date(year=2000, month=None, day=None)\n"
     ]
    }
   ],
   "source": [
    "# –ø—Ä–æ–≤–µ—Ä–∫–∞\n",
    "parser_birth_date = Parser(BIRTH_DATE)\n",
    "\n",
    "text = \"–ò–≤–∞–Ω —Ä–æ–¥–∏–ª—Å—è –≤ 10-05-1980. –£ –ò–≥–æ—Ä—è –¥–µ–Ω—å —Ä–æ–∂–¥–µ–Ω–∏—è 20/04/1990. –ü–µ—Ç—è —Ä–æ–¥–∏–ª—Å—è –≤ 2001 –≥–æ–¥—É. –£ –Ø–Ω—ã –¥–µ–Ω—å —Ä–æ–∂–¥–µ–Ω–∏—è 21 –æ–∫—Ç—è–±—Ä—è. –†–æ–¥–∏–ª—Å—è –≤ 2000 –≥.\"\n",
    "\n",
    "for match in parser_birth_date.findall(text):\n",
    "    print([_.value for _ in match.tokens])\n",
    "    print(match.fact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü—Ä–∞–≤–∏–ª–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –º–µ—Å—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIRTH_PLACE = rule(\n",
    "    dictionary({'–≤', '–∏–∑', '–Ω–∞'}), \n",
    "    gram('ADJF').optional().repeatable(),  # –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω–æ–µ –¥–ª—è –≥–æ—Ä–æ–¥–∞\n",
    "    dictionary({'–≥–æ—Ä–æ–¥', '—Å—Ç—Ä–∞–Ω–∞', '–º–µ—Å—Ç–æ', '—Ä–µ—Å–ø—É–±–ª–∏–∫–∞', '–∫—Ä–∞–π', '—Å–µ–ª–æ', '–¥–µ—Ä–µ–≤–Ω—è', '–æ–∫—Ä—É–≥', '–æ–±–ª–∞—Å—Ç—å', '—Ä–∞–π–æ–Ω'}).optional(),\n",
    "    and_(is_capitalized(),\n",
    "         gram('NOUN')).interpretation(BirthPlace.name.inflected())           # –≥–æ—Ä–æ–¥\n",
    ").interpretation(BirthPlace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['–≤', '–ø—Ä–µ–∫—Ä–∞—Å–Ω–æ–º', '–≥–æ—Ä–æ–¥–µ', '–ö–æ—Å—Ç—Ä–æ–º–∞']\n",
      "Place(name='–∫–æ—Å—Ç—Ä–æ–º–∞')\n",
      "['–∏–∑', '–≥–æ—Ä–æ–¥–∞', '–°–∞–º–∞—Ä–∞']\n",
      "Place(name='—Å–∞–º–∞—Ä–∞')\n",
      "['–≤', '–ø—Ä–µ–∫—Ä–∞—Å–Ω–æ–π', '—Å—Ç—Ä–∞–Ω–µ', '–†–æ—Å—Å–∏—è']\n",
      "Place(name='—Ä–æ—Å—Å–∏—è')\n"
     ]
    }
   ],
   "source": [
    "# –ø—Ä–æ–≤–µ—Ä–∫–∞\n",
    "parser_birth_place = Parser(BIRTH_PLACE)\n",
    "\n",
    "text = \"–ò–≤–∞–Ω —Ä–æ–¥–∏–ª—Å—è –≤ –ø—Ä–µ–∫—Ä–∞—Å–Ω–æ–º –≥–æ—Ä–æ–¥–µ –ö–æ—Å—Ç—Ä–æ–º–∞. –ò–≥–æ—Ä—å —Ä–æ–¥–æ–º –∏–∑ –≥–æ—Ä–æ–¥–∞ –°–∞–º–∞—Ä–∞. –ü–µ—Ç—Ä —Ä–æ–¥–∏–ª—Å—è –≤ –ø—Ä–µ–∫—Ä–∞—Å–Ω–æ–π —Å—Ç—Ä–∞–Ω–µ –†–æ—Å—Å–∏—è\"\n",
    "\n",
    "for match in parser_birth_place.findall(text):\n",
    "    print([_.value for _ in match.tokens])\n",
    "    print(match.fact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –§–∏–Ω–∞–ª—å–Ω–æ–µ –ø—Ä–∞–≤–∏–ª–æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_VERB = dictionary({'—Ä–æ–¥–∏–ª—Å—è', '—Ä–æ–¥–æ–º', '—Ä–æ–∂–¥–µ–Ω–∏–µ'})\n",
    "\n",
    "ENTRY = or_(\n",
    "            rule(NAME.interpretation(Entry.name),\n",
    "                 MAIN_VERB, \n",
    "                 BIRTH_DATE.interpretation(Entry.birth_date),\n",
    "                 MAIN_VERB.optional(), \n",
    "                 BIRTH_PLACE.interpretation(Entry.birth_place)),\n",
    "            rule(NAME.interpretation(Entry.name),\n",
    "                 MAIN_VERB, \n",
    "                 BIRTH_PLACE.interpretation(Entry.birth_place), \n",
    "                 MAIN_VERB.optional(), \n",
    "                 BIRTH_DATE.interpretation(Entry.birth_date)),\n",
    "            rule(MAIN_VERB, \n",
    "                 BIRTH_DATE.interpretation(Entry.birth_date), \n",
    "                 NAME.interpretation(Entry.name), \n",
    "                 MAIN_VERB.optional(), \n",
    "                 BIRTH_PLACE.interpretation(Entry.birth_place)),\n",
    "            rule(MAIN_VERB, \n",
    "                 BIRTH_PLACE.interpretation(Entry.birth_place), \n",
    "                 NAME.interpretation(Entry.name), \n",
    "                 MAIN_VERB.optional(), \n",
    "                 BIRTH_DATE.interpretation(Entry.birth_date)),\n",
    "            rule(MAIN_VERB, \n",
    "                 BIRTH_PLACE.interpretation(Entry.birth_place), \n",
    "                 BIRTH_DATE.interpretation(Entry.birth_date), \n",
    "                 NAME.interpretation(Entry.name)),\n",
    "            rule(MAIN_VERB, \n",
    "                 BIRTH_DATE.interpretation(Entry.birth_date), \n",
    "                 BIRTH_PLACE.interpretation(Entry.birth_place), \n",
    "                 NAME.interpretation(Entry.name))\n",
    "    ).interpretation(\n",
    "        Entry\n",
    "    )\n",
    "\n",
    "parser = Parser(ENTRY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry(name=Person(first_name='–∏–≤–∞–Ω', last_name='–≤–∞–ª–µ–Ω—Ç–∏–Ω–æ–≤'), birth_date=Date(year=2001, month=9, day=21), birth_place=Place(name='–∫–æ—Å—Ç—Ä–æ–º–∞'))\n",
      "Entry(name=Person(first_name='–ø–µ—Ç—è', last_name='–ø–µ—Ç—Ä–æ–≤–∏—á'), birth_date=Date(year=2006, month=10, day=10), birth_place=Place(name='—Ä–æ—Å—Å–∏—è'))\n",
      "Entry(name=Person(first_name='–º–∞–∫—Å–∏–º', last_name=None), birth_date=Date(year=1700, month=10, day=19), birth_place=Place(name='–∫–∞–∑–∞–Ω—å'))\n",
      "Entry(name=Person(first_name='–ø–µ—Ç—è', last_name='—à—É–º–Ω—ã–π'), birth_date=Date(year=2000, month=None, day=None), birth_place=Place(name='–ø–æ–¥–º–æ—Å–∫–æ–≤—å–µ'))\n"
     ]
    }
   ],
   "source": [
    "# –ø—Ä–æ–≤–µ—Ä–∫–∞\n",
    "text = \"–ò–≤–∞–Ω –í–∞–ª–µ–Ω—Ç–∏–Ω–æ–≤ —Ä–æ–¥–∏–ª—Å—è 21 —Å–µ–Ω—Ç—è–±—Ä—è 2001 –≥–æ–¥–∞ –≤ –ö–æ—Å—Ç—Ä–æ–º–µ. \\\n",
    "        –ü–µ—Ç—è –ü–µ—Ç—Ä–æ–≤–∏—á —Ä–æ–¥–∏–ª—Å—è –≤ –†–æ—Å—Å–∏–∏ 10-10-2006. \\\n",
    "        –ú–∞–∫—Å–∏–º —Ä–æ–¥–∏–ª—Å—è 19/10/1700 –≤ –≥–æ—Ä–æ–¥–µ –ö–∞–∑–∞–Ω—å \\\n",
    "        –†–æ–¥–∏–≤—à–∏—Å—å –≤ 2000 –≥–æ–¥—É –≤ –ü–æ–¥–º–æ—Å–∫–æ–≤—å–µ –ü–µ—Ç—è –®—É–º–Ω—ã–π ...\"\n",
    "\n",
    "for match in parser.findall(text):\n",
    "    print(match.fact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Iterator\n",
    "\n",
    "@dataclass\n",
    "class Text:\n",
    "    label: str\n",
    "    title: str\n",
    "    text: str\n",
    "\n",
    "\n",
    "def read_texts(fn: str) -> Iterator[Text]:\n",
    "    with gzip.open(fn, \"rt\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            yield Text(*line.strip().split(\"\\t\"))\n",
    "\n",
    "filepath = '../../data/news.txt.gz'\n",
    "\n",
    "texts = list(read_texts(filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry(name=Person(first_name='–±–µ—Ç—Å–∏', last_name='–ø–∞–ª–º–µ—Ä–∞'), birth_date=Date(year=1926, month=None, day=None), birth_place=Place(name='—Å—à–∞'))\n",
      "Entry(name=Person(first_name='—Ç—Ä—ç–º–∏–µ–ª', last_name=None), birth_date=Date(year=1928, month=None, day=None), birth_place=Place(name='–ø–æ–ª—å—à–∞'))\n",
      "Entry(name=Person(first_name='–¥–º–∏—Ç—Ä–∏–π', last_name='—á–µ—Ä–Ω—è–≤—Å–∫–∏–π'), birth_date=Date(year=1992, month=3, day=5), birth_place=Place(name='–∞—Ä—Ç—ë–º–æ–≤—Å–∫'))\n",
      "Entry(name=Person(first_name='—è–∫–æ–≤–ª–µ–≤—é—Ä–∏–π', last_name='—è–∫–æ–≤–ª–µ–≤'), birth_date=Date(year=1928, month=None, day=None), birth_place=Place(name='–º–æ—Å–∫–≤–∞'))\n",
      "Entry(name=Person(first_name='–ø–∞—Ç—Ä–∏–∫', last_name=None), birth_date=Date(year=1990, month=None, day=None), birth_place=Place(name='–±—Ä–æ–Ω–∫—Å'))\n",
      "Entry(name=Person(first_name='–Ω–∏–∫–æ–ª–∞–π', last_name='–∫–∞—Ä–∞—á–µ–Ω—Ü–æ–≤'), birth_date=Date(year=1944, month=10, day=27), birth_place=Place(name='–º–æ—Å–∫–≤–∞'))\n",
      "Entry(name=Person(first_name='–∏–≥–æ—Ä—å', last_name='–¥–æ—Ü–µ–Ω–∫–æ'), birth_date=Date(year=1953, month=None, day=None), birth_place=Place(name='—É–∫—Ä–∞–∏–Ω–∞'))\n",
      "Entry(name=Person(first_name='—ç–Ω–≥–µ–ª—å–±–∞—Ä—Ç', last_name=None), birth_date=Date(year=1925, month=None, day=None), birth_place=Place(name='—Å—à–∞'))\n",
      "Entry(name=Person(first_name='–∏–Ω–Ω–∞', last_name='–ª–∏—Å–Ω—è–Ω—Å–∫–∞—è'), birth_date=Date(year=1928, month=None, day=None), birth_place=Place(name='–±–∞–∫—É'))\n",
      "Entry(name=Person(first_name='—Ä–∞–π–º–æ–Ω–¥', last_name='–ø–∞—É–ª—Å'), birth_date=Date(year=1936, month=1, day=12), birth_place=Place(name='—Ä–∏–≥–∞'))\n",
      "Entry(name=Person(first_name='—é–ª–∏—è', last_name='–ø–∞—Å—Ç—Ä–∞–Ω–∞'), birth_date=Date(year=1834, month=None, day=None), birth_place=Place(name='–º–µ–∫—Å–∏–∫–∞'))\n",
      "Entry(name=Person(first_name='—ç–¥–≤–∞—Ä–¥', last_name='–º—É–Ω–∫'), birth_date=Date(year=1863, month=12, day=12), birth_place=Place(name='–ª–µ—Ç–µ–Ω'))\n",
      "Entry(name=Person(first_name='—Ç–∞—Ç—å—è–Ω–∞', last_name='—Å–∞–º–æ–π–ª–æ–≤–∞'), birth_date=Date(year=1934, month=5, day=4), birth_place=Place(name='–ª–µ–Ω–∏–Ω–≥—Ä–∞–¥'))\n",
      "Entry(name=Person(first_name='—Ä–∞—Ö–ª–∏–Ω–∞', last_name=None), birth_date=Date(year=1938, month=None, day=None), birth_place=Place(name='–ª–µ–Ω–∏–Ω–≥—Ä–∞–¥'))\n",
      "Entry(name=Person(first_name='–≤–ª–∞–¥–∏–º–∏—Ä', last_name='–≤—ã—Å–æ—Ü–∫–∏–π'), birth_date=Date(year=1938, month=None, day=None), birth_place=Place(name='–º–æ—Å–∫–≤–∞'))\n",
      "Entry(name=Person(first_name='–±–æ—Ä–∏—Å', last_name='–≤–∞—Å–∏–ª—å–µ–≤'), birth_date=Date(year=1924, month=5, day=21), birth_place=Place(name='—Å–º–æ–ª–µ–Ω—Å–∫'))\n",
      "Entry(name=Person(first_name='–ª—É–∏', last_name='–∞–ª–µ–∫—Å–∞–Ω–¥—Ä'), birth_date=Date(year=None, month=7, day=22), birth_place=Place(name='–ª–æ–Ω–¥–æ–Ω'))\n",
      "Entry(name=Person(first_name='–µ–≤–≥–µ–Ω–∏–π', last_name='–≥—Ä–∏—à–∫–æ–≤–µ—Ü'), birth_date=Date(year=1967, month=None, day=None), birth_place=Place(name='–∫–µ–º–µ—Ä–æ–≤–æ'))\n",
      "Entry(name=Person(first_name='—Å—Ç–∞–¥–Ω–∏–∫', last_name='–ª–µ–æ–Ω–∏–¥'), birth_date=Date(year=1971, month=None, day=None), birth_place=Place(name='–ø–æ–¥–æ–ª—è–Ω–µ—Ü'))\n",
      "Entry(name=Person(first_name='–∑–∏–Ω–∞–∏–¥–∞', last_name='—Å–µ—Ä–µ–±—Ä—è–∫–æ–≤–∞'), birth_date=Date(year=1913, month=6, day=28), birth_place=Place(name='—Å–µ–ª–æ'))\n",
      "Entry(name=Person(first_name='–∏–≥–æ—Ä—å', last_name='–∫–≤–∞—à–∞'), birth_date=Date(year=1933, month=None, day=None), birth_place=Place(name='–º–æ—Å–∫–≤–∞'))\n",
      "Entry(name=Person(first_name='–ø–æ–ª–∏–Ω–∞', last_name='–∂–µ—Ä–µ–±—Ü–æ–≤–∞'), birth_date=Date(year=1985, month=None, day=None), birth_place=Place(name='–≥—Ä–æ–∑–Ω—ã–π'))\n",
      "Entry(name=Person(first_name='–∞–ª–µ–∫—Å–µ–π', last_name='—Ä–µ–º–∏–∑–æ–≤'), birth_date=Date(year=1877, month=None, day=None), birth_place=Place(name='–º–æ—Å–∫–≤–∞'))\n",
      "Entry(name=Person(first_name='–º–∏—Ö–∞–∏–ª', last_name='–∞–ª–≥–∞—à'), birth_date=Date(year=1988, month=None, day=None), birth_place=Place(name='–æ–º—Å–∫'))\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "for text in tqdm(texts, disable=True):\n",
    "    try:\n",
    "        for match in parser.findall(text.text):\n",
    "         print(match.fact)\n",
    "    except:\n",
    "       # empty\n",
    "       pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24 —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –î–æ–ø–æ–ª–Ω–µ–Ω–∏–µ\n",
    "\n",
    "–í natasha –µ—Å—Ç—å [–≥–æ—Ç–æ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏](https://habr.com/ru/articles/349864/#:~:text=%D0%BF%D0%BE%D0%BC%D0%BE%D1%89%D1%8C%D1%8E%20Yargy%2D%D0%BF%D0%B0%D1%80%D1%81%D0%B5%D1%80%D0%B0.-,%D0%93%D0%BE%D1%82%D0%BE%D0%B2%D1%8B%D0%B5%20%D0%BF%D1%80%D0%B0%D0%B2%D0%B8%D0%BB%D0%B0,-%D0%A1%D0%B5%D0%B9%D1%87%D0%B0%D1%81%20%D0%B2%20Natasha) –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AddressExtractor' from 'natasha' (/home/ffrankusha/study/university/nlp-course/venv/lib/python3.10/site-packages/natasha/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnatasha\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     NamesExtractor,\n\u001b[1;32m      3\u001b[0m     AddressExtractor,\n\u001b[1;32m      4\u001b[0m     DatesExtractor,\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      7\u001b[0m extractors \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      8\u001b[0m     NamesExtractor(),\n\u001b[1;32m      9\u001b[0m     AddressExtractor(),\n\u001b[1;32m     10\u001b[0m     DatesExtractor(),\n\u001b[1;32m     11\u001b[0m ]\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'AddressExtractor' from 'natasha' (/home/ffrankusha/study/university/nlp-course/venv/lib/python3.10/site-packages/natasha/__init__.py)"
     ]
    }
   ],
   "source": [
    "from natasha import (\n",
    "    NamesExtractor,\n",
    "    AddressExtractor,\n",
    "    DatesExtractor,\n",
    ")\n",
    "\n",
    "extractors = [\n",
    "    NamesExtractor(),\n",
    "    AddressExtractor(),\n",
    "    DatesExtractor(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–æ–∑–º–æ–∂–Ω–æ, –∏—Ö –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —É–ø—Ä–æ—Å—Ç–∏–ª–æ –±—ã –∑–∞–¥–∞—á—É üòÉ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
